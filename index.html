<script src="http://www.google.com/jsapi" type="text/javascript"></script>
<script type="text/javascript">google.load("jquery", "1.3.2");</script>
<link href="https://fonts.googleapis.com/css2?family=Lato&display=swap" rel="stylesheet">
<link rel="stylesheet" type="text/css" href="./resources/style.css" media="screen"/>

<html lang="en">
<head>
	<title> FilterPrompt </title>
    <!-- Facebook automatically scrapes this. Go to https://developers.facebook.com/tools/debug/
        if you update and want to force Facebook to re-scrape. -->
	<meta property="og:image" content="./resources/share.png"/>
	<meta property="og:title" content="FilterPrompt" />
	<meta property="og:description" content="We introduce FilterPrompt, an approach aimed at enhancing control within diffusion models." />
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <meta charset="UTF-8">


    <!-- Add your Google Analytics tag here -->
    <!--
    <script async
            src="https://www.googletagmanager.com/gtag/js?id=UA-97476543-1"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag() {
            dataLayer.push(arguments);
        }
        gtag('js', new Date());
        gtag('config', 'UA-97476543-1');
    </script>
    -->
   
    <script src="https://kit.fontawesome.com/d814472bd3.js" crossorigin="anonymous"></script>
    <link href="https://fonts.googleapis.com/css2?family=Lato:wght@400;700&display=swap" rel="stylesheet">

    

  
</head>

<body>
<div class="container">
    
    <div id="bg">
    
        <div class="title">
            FilterPrompt:
        </div>
        
        <div class="title">
            Guiding Image Transfer in Diffusion Models
        </div>
        
        <br> 
        <br>
        <br>

        <div class="author">
            <a href="https://meaoxixi.github.io/about/" target="_blank">Xi Wang</a><sup>1</sup>
        </div>
        <div class="author">
            <a href="https://sites.google.com/view/yichen-peng/home" target="_blank">Yichen Peng</a><sup>2</sup>
        </div>
        <div class="author">
            <a href="https://www.kth.se/profile/hfang" target="_blank">Heng Fang</a><sup>3</sup>
        </div>
        <div class="author">
            <a href="http://www.jaist.ac.jp/~xie/" target="_blank">Haoran Xie</a><sup>4</sup>
        </div>
        <div class="author">
            <a href="https://keepthinkingyx.github.io/Xi-Yang/" target="_blank">Xi Yang*</a><sup>1*</sup>
        </div>
        <div class="author">
                <a href="https://gujisuo.jlu.edu.cn/info/1032/1156.htm" target="_blank">Chuntao	Li</a><sup>5</sup>
        </div>

        <div class="row">
            <ul class="inline-list text-secondary font-sans hover:text-primary dark:text-white" style="list-style-type: none;">
                <li><sup>1</sup>School of Artificial intelligence, Jilin University</li>
                <li><sup>2</sup>Tokyo Institute of Technology</li>
                <li><sup>3</sup>KTH Royal Institute of Technology</li>
                <li><sup>4</sup>Japan Advanced Institute of Science and Technology (JAIST)</li>
                <li><sup>5</sup>School of Archaeology, Jilin University</li>
            </ul>
        </div>
        


        <br>
        <br>

        <span class="link-block">
            <a href="https://arxiv.org/abs/2404.13263" target="_blank"
            class="external-link button is-normal is-rounded is-dark">
            <span class="icon" style="position: relative; top: 4px;">
                <i class="fas fa-file-pdf"></i>
            </span>
            <span>Paper</span>
            </a>
        </span>

        <span class="link-block">
            <a href="https://github.com/Meaoxixi/FilterPrompt" target="_blank"
            class="external-link button is-normal is-rounded is-dark">
            <span class="icon" style="position: relative; top: 4px;">
                <i class="fab fa-github"></i>
            </span>
            <span style="margin-left: 2px;">Code</span>
            </a>
        </span>


        <span class="link-block">
            <a href=""
            class="external-link button is-normal is-rounded is-dark">
            <span class="icon" style="position: relative; top: 3px; ">
                <i class="fa-solid fa-robot"></i>
            </span >
            <span style="margin-left: 4px;">Demo</span>
            </a>
        </span> 
        <br>
        <br>

    </div>
    
    <!-- <div class="links"><a href="">[More effects]</a></div> -->
    

    <br>
    <br>
    <div class="teaser">
        <img src="./resources/teaser.png" 
                alt="Teaser figure." 
                style="width: 100%; text-align: center;" />
        
        
        <!-- <br>
        <i>
            This template was originally made for <a href="http://richzhang.github.io/colorization/">
            Colorful Image Colorization</a>. It was adapted to be mobile responsive for
            <a href="https://jasonyzhang.com/phosa/">PHOSA</a>. Try resizing this webpage
            or opening it on your mobile device. The code can be found in
            <a href="https://github.com/jasonyzhang/webpage-template"> this repo</a>.
        </i> -->
    </div>

    <br><br>
    <hr>

    <!-- <h1>Abstract</h1>
    <p>
        In controllable generation tasks, flexibly manipulating the generated images to attain a desired appearance or structure based on a single input image cue remains a critical and longstanding challenge. 
        Achieving this requires the effective decoupling of key attributes within the input image data, in order to get representations accurately. 
        Previous research has concentrated predominantly on disentangling image attributes within feature space. 
        However, the complex distribution present in real-world data often makes the application of such decoupling algorithms to other datasets challenging. 
        Moreover, the granularity of control over feature encoding frequently fails to meet specific task requirements. 
        Upon scrutinizing the characteristics of various generative models, we have observed that the input sensitivity and dynamic evolution properties of the diffusion model can be effectively fused with the explicit decomposition operation in pixel space. 
        This allows the operation that we design and use in pixel space to achieve the desired control effect on the specific representation in the generated results. 
        This integration enables the image processing operations performed in pixel space for a specific feature distribution of the input image, and can achieve the desired control effect in the generated results. 
        Therefore, we propose FilterPrompt, an approach to enhance the effect of controllable generation. It can be universally applied to any diffusion model, allowing users to adjust the representation of specific image features in accordance with task requirements, thereby facilitating more precise and controllable generation outcomes. 
        In particular, our designed experiments demonstrate that the FilterPrompt optimizes feature correlation, mitigates content conflicts during the generation process, and enhances the effect of controllable generation. 
        Therefore, we propose FilterPrompt, an approach to enhance the model control effect. 
        It can be universally applied to any diffusion model, allowing users to adjust the representation of specific image features in accordance with task requirements, thereby facilitating more precise and controllable generation outcomes. 
        In particular, our designed experiments demonstrate that the FilterPrompt optimizes feature correlation, mitigates content conflicts during the generation process, and enhances the model's control capability.
    </p> -->
    <!-- <h1 style="font-size: 24px;">Abstract</h1> -->
    <h1>Abstract</h1>
    <p style="text-align: justify; font-size: 16px;">
    In controllable generation tasks, flexibly manipulating the generated images to attain a desired appearance or structure based on a single input image cue remains a critical and longstanding challenge. Achieving this requires the effective decoupling of key attributes within the input image data, in order to get representations accurately. Previous research has concentrated predominantly on disentangling image attributes within feature space. However, the complex distribution present in real-world data often makes the application of such decoupling algorithms to other datasets challenging. Moreover, the granularity of control over feature encoding frequently fails to meet specific task requirements. Upon scrutinizing the characteristics of various generative models, we have observed that the input sensitivity and dynamic evolution properties of the diffusion model can be effectively fused with the explicit decomposition operation in pixel space. This allows the operation that we design and use in pixel space to achieve the desired control effect on the specific representation in the generated results. This integration enables the image processing operations performed in pixel space for a specific feature distribution of the input image, and can achieve the desired control effect in the generated results. Therefore, we propose FilterPrompt, an approach to enhance the effect of controllable generation. It can be universally applied to any diffusion model, allowing users to adjust the representation of specific image features in accordance with task requirements, thereby facilitating more precise and controllable generation outcomes. In particular, our designed experiments demonstrate that the FilterPrompt optimizes feature correlation, mitigates content conflicts during the generation process, and enhances the effect of controllable generation. Therefore, we propose FilterPrompt, an approach to enhance the model control effect. It can be universally applied to any diffusion model, allowing users to adjust the representation of specific image features in accordance with task requirements, thereby facilitating more precise and controllable generation outcomes. In particular, our designed experiments demonstrate that the FilterPrompt optimizes feature correlation, mitigates content conflicts during the generation process, and enhances the model's control capability.
    </p>


    <br><br><hr>

    <!-- <br><br><hr><br> -->

    <h1>Applications</h1>

    <br>

    <div class="image-container">
        
          
        <div class="imageshow6">
            <div id="slider">
                <div class="slides">
                    <div class="slide"><img src=".\resources\at1.png" alt="Image 1" width="3052" height="863"></div>
                    <div class="slide"><img src=".\resources\at2.png" alt="Image 2" width="3052" height="863"></div>
                    <div class="slide"><img src=".\resources\at3.png" alt="Image 3" width="3052" height="863"></div>
                    <div class="slide"><img src=".\resources\at4.png" alt="Image 4" width="3052" height="996"></div>
                    <div class="slide"><img src=".\resources\at5.png" alt="Image 5" width="3052" height="625"></div>
                    <div class="slide"><img src=".\resources\at6.png" alt="Image 6" width="3052" height="603"></div>
                </div>
                <button id="prev" onclick="prevSlide()">&#9664;</button>
                <button id="next" onclick="nextSlide()">&#9654;</button>
            </div>
            
            <script>
                let currentIndex = 0;
                const slides = document.querySelectorAll('.slide');
                
                function showSlide(index) {
                    if (index < 0) {
                        index = slides.length - 1;
                    } else if (index >= slides.length) {
                        index = 0;
                    }
                    const offset = -index * 16.666; 
                    document.querySelector('.slides').style.transform = `translateX(${offset}%)`;
                    currentIndex = index;
                }
                
                function prevSlide() {
                    showSlide(currentIndex - 1);
                }
                
                function nextSlide() {
                    showSlide(currentIndex + 1);
                }
            </script>
            <p style="text-align: justify; font-size: 16px; margin-top: 20px;"><span style="font-weight: bold;">Style transfer tasks:</span> Our focus is to obtain the low-level texture features from the style image without semantic correspondence and then render it to the content image.</p>
        </div>

        <br><br>
        <br><br>

        <div class="imageshow3">
            <div id="slider1">
                <div class="slides1">
                    <div class="slide1"><img src=".\resources\st1.png" alt="Image 1" width="7354" height="1699"></div>
                    <div class="slide1"><img src=".\resources\st2.png" alt="Image 2" width="7354" height="1557"></div>
                    <div class="slide1"><img src=".\resources\st3.png" alt="Image 3" width="7354" height="1243"></div>
                </div>
                <button id="prev1" onclick="prevSlide1()">&#9664;</button>
                <button id="next1" onclick="nextSlide1()">&#9654;</button>
            </div>
            
            <script>
                let currentIndex1 = 0;
                const slides1 = document.querySelectorAll('.slide1');
                
                function showSlide1(index) {
                    if (index < 0) {
                        index = slides1.length - 1;
                    } else if (index >= slides1.length) {
                        index = 0;
                    }
                    const offset1 = -index * 33.333; 
                    document.querySelector('.slides1').style.transform = `translateX(${offset1}%)`;
                    currentIndex1 = index;
                }
                
                function prevSlide1() {
                    showSlide1(currentIndex1 - 1);
                }
                
                function nextSlide1() {
                    showSlide1(currentIndex1 + 1);
                }
            </script>
            <p style="text-align: justify; font-size: 16px; margin-top: 20px;"><span style="font-weight: bold;">Appearance transformation tasks:</span> A total of six domains (cat, dog, wild, bird, airplane, car), we showcase the effects achieved by the baseline architecture with filtering combined operation in local, object-centric, and full-image-level appearance transfer tasks.</p>
        </div>
            
            
    
    
    </div>
    

    <br><br><hr>

    <h1>Code</h1>
    <a href="https://github.com/Meaoxixi/FilterPrompt" target="_blank">
        <img style="width:80%;" src="./resources/method_diagram.png"
             alt="Model overview figure"/>
    </a>
    <br>
    
    <span class="link-block">
        <a href="https://github.com/Meaoxixi/FilterPrompt" target="_blank"
        class="external-link button is-normal is-rounded is-dark">
        <span class="icon" style="position: relative; top: 3px;">
            <i class="fab fa-github"></i>
        </span>
        <span>Github</span>
        </a>
    </span>

    <br><br><hr>

    <h1>Paper</h1>

    <div class="paper-thumbnail">
        <a href="https://arxiv.org/abs/2404.13263" target="_blank">
            <img class="layered-paper-big" width="100%" src="./resources/paper.png" alt="Paper thumbnail."/>
        </a>
    </div>
    <div class="paper-info">
        <h4>FilterPrompt: Guiding Image Transfer in Diffusion Models</h4>
        <h5>
            Xi Wang and Yichen Peng and Heng Fang and Haoran Xie and Xi Yang and Chuntao Li
        </h5>
        <pre><code>
            @article{wang2024filterprompt,
                title={FilterPrompt: Guiding Image Transfer in Diffusion Models},
                author={Wang, Xi and Peng, Yichen and Fang, Heng and Xie, Haoran and Yang, Xi and Li, Chuntao},
                journal={arXiv preprint arXiv:2404.13263},
                year={2024}
              }
        </code></pre>
    </div>

    <br><br><hr>
    <!-- <h1>Acknowledgements</h1> -->
    <p>
        This template was originally made by <a href="http://web.mit.edu/phillipi/" target="_blank">Phillip Isola</a>
        and <a href="http://richzhang.github.io/" target="_blank">Richard Zhang</a> for a
        <a href="http://richzhang.github.io/colorization/" target="_blank">colorful</a> ECCV project. It was
        adapted to be mobile responsive by <a href="https://jasonyzhang.com/" target="_blank">Jason Zhang</a>
        for <a href="https://jasonyzhang.com/phosa/" target="_blank">PHOSA</a>. The code can be found
        <a href="https://github.com/jasonyzhang/webpage-template" target="_blank">here</a>.
    </p>

    <br><br>
</div>

</body>

</html>
