<script src="http://www.google.com/jsapi" type="text/javascript"></script>
<script type="text/javascript">google.load("jquery", "1.3.2");</script>
<link href="https://fonts.googleapis.com/css2?family=Lato&display=swap" rel="stylesheet">
<link rel="stylesheet" type="text/css" href="./resources/style.css" media="screen"/>

<html lang="en">
<head>
	<title> FilterPrompt </title>
    <!-- Facebook automatically scrapes this. Go to https://developers.facebook.com/tools/debug/
        if you update and want to force Facebook to re-scrape. -->
	<meta property="og:image" content="./resources/share.png"/>
	<meta property="og:title" content="FilterPrompt" />
	<meta property="og:description" content="We introduce FilterPrompt, an approach aimed at enhancing control within diffusion models." />
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <!-- Add your Google Analytics tag here -->
    <!--
    <script async
            src="https://www.googletagmanager.com/gtag/js?id=UA-97476543-1"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag() {
            dataLayer.push(arguments);
        }
        gtag('js', new Date());
        gtag('config', 'UA-97476543-1');
    </script>
    -->

</head>

<body>
<div class="container">
    <div class="title">
        FilterPrompt: Guiding Image Transfer in Diffusion Models
    </div>

    <br>
    <br>

    <div class="author">
        <a href="">Xi Wang</a><sup>1</sup>
    </div>
    <div class="author">
        <a href="https://sites.google.com/view/yichen-peng/home" target="_blank">Yichen Peng</a><sup>2</sup>
    </div>
    <div class="author">
        <a href="https://www.kth.se/profile/hfang" target="_blank">Heng Fang</a><sup>3</sup>
    </div>
    <div class="author">
        <a href="http://www.jaist.ac.jp/~xie/" target="_blank">Haoran Xie</a><sup>4</sup>
    </div>
    <div class="author">
        <a href="https://keepthinkingyx.github.io/Xi-Yang/" target="_blank">Xi Yang*</a><sup>1*</sup>
    </div>
    <div class="author">
            <a href="https://gujisuo.jlu.edu.cn/info/1032/1156.htm" target="_blank">Chuntao	Li</a><sup>5</sup>
    </div>

    <br>
    <br>

    <div class="links"><a href="https://arxiv.org/abs/2404.13263" target="_blank">[Paper]</a></div>
    <div class="links"><a href="https://github.com/Meaoxixi/FilterPrompt" target="_blank">[Code]</a></div>
    <div class="links"><a href="">[Demo]</a></div>
    <!-- <div class="links"><a href="">[More effects]</a></div> -->
    

    <br>
    <br>
    <div class="teaser">
        <img src="./resources/teaser.png" 
                alt="Teaser figure." 
                style="width: 120%; text-align: center;" />
        
        
        <!-- <br>
        <i>
            This template was originally made for <a href="http://richzhang.github.io/colorization/">
            Colorful Image Colorization</a>. It was adapted to be mobile responsive for
            <a href="https://jasonyzhang.com/phosa/">PHOSA</a>. Try resizing this webpage
            or opening it on your mobile device. The code can be found in
            <a href="https://github.com/jasonyzhang/webpage-template"> this repo</a>.
        </i> -->
    </div>

    <br><br>
    <hr>

    <!-- <h1>Abstract</h1>
    <p>
        In controllable generation tasks, flexibly manipulating the generated images to attain a desired appearance or structure based on a single input image cue remains a critical and longstanding challenge. 
        Achieving this requires the effective decoupling of key attributes within the input image data, in order to get representations accurately. 
        Previous research has concentrated predominantly on disentangling image attributes within feature space. 
        However, the complex distribution present in real-world data often makes the application of such decoupling algorithms to other datasets challenging. 
        Moreover, the granularity of control over feature encoding frequently fails to meet specific task requirements. 
        Upon scrutinizing the characteristics of various generative models, we have observed that the input sensitivity and dynamic evolution properties of the diffusion model can be effectively fused with the explicit decomposition operation in pixel space. 
        This allows the operation that we design and use in pixel space to achieve the desired control effect on the specific representation in the generated results. 
        This integration enables the image processing operations performed in pixel space for a specific feature distribution of the input image, and can achieve the desired control effect in the generated results. 
        Therefore, we propose FilterPrompt, an approach to enhance the effect of controllable generation. It can be universally applied to any diffusion model, allowing users to adjust the representation of specific image features in accordance with task requirements, thereby facilitating more precise and controllable generation outcomes. 
        In particular, our designed experiments demonstrate that the FilterPrompt optimizes feature correlation, mitigates content conflicts during the generation process, and enhances the effect of controllable generation. 
        Therefore, we propose FilterPrompt, an approach to enhance the model control effect. 
        It can be universally applied to any diffusion model, allowing users to adjust the representation of specific image features in accordance with task requirements, thereby facilitating more precise and controllable generation outcomes. 
        In particular, our designed experiments demonstrate that the FilterPrompt optimizes feature correlation, mitigates content conflicts during the generation process, and enhances the model's control capability.
    </p> -->
    <h1 style="font-size: 24px;">Abstract</h1>
    <p style="text-align: justify; font-size: 16px; background-color: lightgreen;">
    In controllable generation tasks, flexibly manipulating the generated images to attain a desired appearance or structure based on a single input image cue remains a critical and longstanding challenge. Achieving this requires the effective decoupling of key attributes within the input image data, in order to get representations accurately. Previous research has concentrated predominantly on disentangling image attributes within feature space. However, the complex distribution present in real-world data often makes the application of such decoupling algorithms to other datasets challenging. Moreover, the granularity of control over feature encoding frequently fails to meet specific task requirements. Upon scrutinizing the characteristics of various generative models, we have observed that the input sensitivity and dynamic evolution properties of the diffusion model can be effectively fused with the explicit decomposition operation in pixel space. This allows the operation that we design and use in pixel space to achieve the desired control effect on the specific representation in the generated results. This integration enables the image processing operations performed in pixel space for a specific feature distribution of the input image, and can achieve the desired control effect in the generated results. Therefore, we propose FilterPrompt, an approach to enhance the effect of controllable generation. It can be universally applied to any diffusion model, allowing users to adjust the representation of specific image features in accordance with task requirements, thereby facilitating more precise and controllable generation outcomes. In particular, our designed experiments demonstrate that the FilterPrompt optimizes feature correlation, mitigates content conflicts during the generation process, and enhances the effect of controllable generation. Therefore, we propose FilterPrompt, an approach to enhance the model control effect. It can be universally applied to any diffusion model, allowing users to adjust the representation of specific image features in accordance with task requirements, thereby facilitating more precise and controllable generation outcomes. In particular, our designed experiments demonstrate that the FilterPrompt optimizes feature correlation, mitigates content conflicts during the generation process, and enhances the model's control capability.
    </p>


    <br><br><hr>

    <!-- <br><br><hr><br> -->

    <h1>Applications</h1>

    <div class="image-container">
        <img style="width:80%; margin-top: 10px; margin-bottom: 20px;"
                src="./resources/5_2_2_appearance_Tansfer.png" 
                alt="Style transfer tasks: Our focus is to obtain the low-level texture features from the style image without semantic correspondence and then render it to the content image." 
                style="display: block;">
        <p style="text-align: justify; font-size: 16px; margin-top: 20px;">Style transfer tasks: Our focus is to obtain the low-level texture features from the style image without semantic correspondence and then render it to the content image.</p>
       
        <img style="width:80%; margin-top: 60px; margin-bottom: 20px;"
                src="./resources/5_2_1_style_Tansfer.png" 
                alt="Appearance transformation tasks: A total of six domains (cat, dog, wild, bird, airplane, car), we showcase the effects achieved by the baseline architecture with filtering combined operation in local, object-centric, and full-image-level appearance transfer tasks." 
                style="display: block;">
        <p style="text-align: justify; font-size: 16px; margin-top: 20px;">Appearance transformation tasks: A total of six domains (cat, dog, wild, bird, airplane, car), we showcase the effects achieved by the baseline architecture with filtering combined operation in local, object-centric, and full-image-level appearance transfer tasks.</p>
    </div>
    

    <br><br><hr>

    <h1>Code</h1>
    <a href="https://github.com/Meaoxixi/FilterPrompt" target="_blank">
        <img style="width:80%;" src="./resources/method_diagram.png"
             alt="Model overview figure"/>
    </a>
    <br>
    <a class="links" href="https://github.com/Meaoxixi/FilterPrompt" target="_blank">[GitHub]</a>

    <br><br><hr>

    <h1>Paper</h1>

    <div class="paper-thumbnail">
        <a href="https://arxiv.org/abs/2404.13263" target="_blank">
            <img class="layered-paper-big" width="100%" src="./resources/paper.png" alt="Paper thumbnail."/>
        </a>
    </div>
    <div class="paper-info">
        <h4>FilterPrompt: Guiding Image Transfer in Diffusion Models</h4>
        <h5>
            Xi Wang and Yichen Peng and Heng Fang and Haoran Xie and Xi Yang and Chuntao Li
        </h5>
        <pre><code>
        @misc{wang2024filterprompt,
            title={FilterPrompt: Guiding Image Transfer in Diffusion Models}, 
            author={Xi Wang and Yichen Peng and Heng Fang and Haoran Xie and Xi Yang and Chuntao Li},
            year={2024},
            eprint={2404.13263},
            archivePrefix={arXiv},
            primaryClass={cs.CV}
        }
        </code></pre>
    </div>

    <br><br><hr>
    <!-- <h1>Acknowledgements</h1> -->
    <p>
        This template was originally made by <a href="http://web.mit.edu/phillipi/" target="_blank">Phillip Isola</a>
        and <a href="http://richzhang.github.io/" target="_blank">Richard Zhang</a> for a
        <a href="http://richzhang.github.io/colorization/" target="_blank">colorful</a> ECCV project. It was
        adapted to be mobile responsive by <a href="https://jasonyzhang.com/" target="_blank">Jason Zhang</a>
        for <a href="https://jasonyzhang.com/phosa/" target="_blank">PHOSA</a>. The code can be found
        <a href="https://github.com/jasonyzhang/webpage-template" target="_blank">here</a>.
    </p>

    <br><br>
</div>

</body>

</html>
